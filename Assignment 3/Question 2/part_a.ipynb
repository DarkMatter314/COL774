{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x_path, y_path):\n",
    "    '''\n",
    "    Args:\n",
    "        x_path: path to x file\n",
    "        y_path: path to y file\n",
    "    Returns:\n",
    "        x: np array of [NUM_OF_SAMPLES x n]\n",
    "        y: np array of [NUM_OF_SAMPLES]\n",
    "    '''\n",
    "    x = np.load(x_path)\n",
    "    y = np.load(y_path)\n",
    "\n",
    "    y = y.astype('float')\n",
    "    x = x.astype('float')\n",
    "\n",
    "    #normalize x:\n",
    "    x = 2*(0.5 - x/255)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(y_true, y_pred):\n",
    "    '''\n",
    "    Args:\n",
    "        y_true: np array of [NUM_SAMPLES x r] (one hot) \n",
    "                or np array of [NUM_SAMPLES]\n",
    "        y_pred: np array of [NUM_SAMPLES x r] (one hot) \n",
    "                or np array of [NUM_SAMPLES]\n",
    "                \n",
    "    '''\n",
    "    results = classification_report(y_pred, y_true)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_path = './x_train.npy'\n",
    "y_train_path = './y_train.npy'\n",
    "\n",
    "X_train, y_train = get_data(x_train_path, y_train_path)\n",
    "\n",
    "x_test_path = './x_test.npy'\n",
    "y_test_path = './y_test.npy'\n",
    "\n",
    "X_test, y_test = get_data(x_test_path, y_test_path)\n",
    "\n",
    "#you might need one hot encoded y in part a,b,c,d,e\n",
    "label_encoder = OneHotEncoder(sparse_output = False)\n",
    "label_encoder.fit(np.expand_dims(y_train, axis = -1))\n",
    "\n",
    "y_train_onehot = label_encoder.transform(np.expand_dims(y_train, axis = -1))\n",
    "y_test_onehot = label_encoder.transform(np.expand_dims(y_test, axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1024)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_new = np.argmax(y_test_onehot, axis = 1)\n",
    "y_train_new = np.argmax(y_train_onehot, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(x):\n",
    "    # if x = 0 derivative is 0.5\n",
    "    y = np.copy(x)\n",
    "    y[x < 0] = 0\n",
    "    y[x == 0] = 0.5\n",
    "    y[x > 0] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.W = np.random.randn(input_size, output_size)\n",
    "        self.b = np.random.randn(output_size)\n",
    "        self.activation = activation\n",
    "        self.dW = np.zeros((input_size, output_size))\n",
    "        self.db = np.zeros(output_size)\n",
    "        self.da = np.zeros(input_size)\n",
    "        self.dz = np.zeros(output_size)\n",
    "        self.x = np.zeros(input_size)\n",
    "        self.z = np.zeros(output_size)\n",
    "        self.a = np.zeros(input_size)\n",
    "\n",
    "    def linear(self, x):\n",
    "        self.x = x\n",
    "        return np.dot(x, self.W) + self.b\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z = self.linear(x)\n",
    "        if(self.activation == 0): self.a = sigmoid(self.z)\n",
    "        else: self.a = relu(self.z)\n",
    "        return self.a\n",
    "    \n",
    "    def backward(self, da):\n",
    "        if(self.activation == 0): self.dz = da * sigmoid_derivative(self.z)\n",
    "        else: self.dz = da * relu_derivative(self.z)\n",
    "        self.dW = np.dot(self.x.T, self.dz)\n",
    "        self.db = np.sum(self.dz, axis = 0)\n",
    "        self.da = np.dot(self.dz, self.W.T)\n",
    "        return self.da \n",
    "\n",
    "    def opbackward(self, dz):\n",
    "        self.dz = dz\n",
    "        self.dW = np.dot(self.x.T, self.dz)\n",
    "        self.db = np.sum(self.dz, axis = 0)\n",
    "        self.da = np.dot(self.dz, self.W.T)\n",
    "        return self.da \n",
    "    \n",
    "    def update(self, lr, batch_size):\n",
    "        self.W -= lr * self.dW / batch_size\n",
    "        self.b -= lr * self.db / batch_size\n",
    "\n",
    "    def clearGradients(self):\n",
    "        self.dW = np.zeros((self.input_size, self.output_size))\n",
    "        self.db = np.zeros(self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_sizes, activation = 0, adaptive_lr = False):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.layers = []\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "        self.activation = activation\n",
    "        self.adaptive_lr = adaptive_lr\n",
    "        if(len(hidden_sizes) == 0):\n",
    "            self.layers.append(Layer(input_size, output_size, activation))\n",
    "            return\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                self.layers.append(Layer(input_size, hidden_sizes[i], activation))\n",
    "            else:\n",
    "                self.layers.append(Layer(hidden_sizes[i-1], hidden_sizes[i], activation))\n",
    "        self.layers.append(Layer(hidden_sizes[-1], output_size, activation))\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer.forward(x)\n",
    "        return softmax(self.layers[-1].linear(x))\n",
    "    \n",
    "    def loss(self, y_pred, y_true):\n",
    "        # cross entropy loss\n",
    "        return - np.sum(y_true * np.log(y_pred + 1e-8)) / len(y_pred)\n",
    "    \n",
    "    def evaluate_set(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_pred = np.argmax(y_pred, axis = 1)\n",
    "        y_true = np.argmax(y, axis = 1)\n",
    "        return np.sum(y_pred == y_true) / len(y_true)\n",
    "    \n",
    "    def backpropogate(self, x, y, lr = 0.01, batch_size = 32):\n",
    "        y_pred = self.predict(x)\n",
    "        dz = y_pred - y\n",
    "        da = self.layers[-1].opbackward(dz)\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            da = layer.backward(da)\n",
    "        for layer in self.layers:\n",
    "            layer.update(lr, batch_size)\n",
    "        for layer in self.layers:\n",
    "            layer.clearGradients()\n",
    "\n",
    "    def train(self, x_train, y_train, epochs = 1000, mini_batch_size = 32, lr = 0.01):\n",
    "        prev_loss = 0\n",
    "        new_loss = 0\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, len(x_train), mini_batch_size):\n",
    "                x_batch = x_train[i:i+mini_batch_size]\n",
    "                y_batch = y_train[i:i+mini_batch_size]\n",
    "                y_pred = self.predict(x_batch)\n",
    "                prev_loss = new_loss\n",
    "                new_loss = self.loss(y_pred, y_batch)\n",
    "                # if(prev_loss - new_loss < 1e-6 and epoch > 100):\n",
    "                #     break\n",
    "                if(self.adaptive_lr == True): self.backpropogate(x_batch, y_batch, lr/sqrt(epoch+1))\n",
    "                else: self.backpropogate(x_batch, y_batch, lr)\n",
    "            if epoch % 10 == 0:\n",
    "                # train_accuracy = self.evaluate_set(x_train, y_train)\n",
    "                # test_accuracy = self.evaluate_set(X_test, y_test_onehot)\n",
    "                # self.accuracies.append((epoch, train_accuracy, test_accuracy))\n",
    "                print(f\"Epoch = {epoch}\")\n",
    "            # if(prev_loss - new_loss < 1e-6 and epoch > 100):\n",
    "            #     break\n",
    "            # if epoch % 10 == 0:\n",
    "                # print(\"Epoch: {}, Loss: {}\".format(epoch, loss))\n",
    "                # self.accuracies.append(self.evaluate(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Node Size: 1\n",
      "Trained Node Size: 1\n",
      "Starting Node Size: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Garv\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Node Size: 5\n",
      "Starting Node Size: 10\n",
      "Trained Node Size: 10\n",
      "Starting Node Size: 100\n",
      "Trained Node Size: 100\n"
     ]
    }
   ],
   "source": [
    "node_sizes = [1, 5, 10, 100]\n",
    "outfile = open('part_b_all.txt', 'w')\n",
    "\n",
    "for node_size in node_sizes:\n",
    "    nn_node = NeuralNetwork(1024, 5, [node_size])\n",
    "    print(f\"Starting Node Size: {node_size}\")\n",
    "    nn_node.train(X_train, y_train_onehot, epochs = 1000, mini_batch_size = 32, lr = 0.01)\n",
    "    print(f\"Trained Node Size: {node_size}\")\n",
    "    y_pred = nn_node.predict(X_test)\n",
    "    y_pred_new = np.argmax(y_pred, axis = 1)\n",
    "    precision = precision_score(y_test_new, y_pred_new, average=None)\n",
    "    recall = recall_score(y_test_new, y_pred_new, average=None)\n",
    "    f1 = f1_score(y_test_new, y_pred_new, average=None)\n",
    "    accuracy = np.sum(y_pred_new == y_test_new) / len(y_test_new)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    outfile.write(f\"Node Size: {node_size}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\nAccuracy: {accuracy}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Architecture: [512, 256, 128, 64]\n",
      "Trained Architecture: [512, 256, 128, 64]\n",
      "Accuracy: 0.729\n",
      "Train Accuracy: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Garv\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Garv\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "part_c_file = open('part_c_last.txt', 'w')\n",
    "architectures = [[512, 256, 128, 64]]\n",
    "\n",
    "for architecture in architectures:\n",
    "    nn_arch = NeuralNetwork(1024, 5, architecture)\n",
    "    print(f\"Starting Architecture: {architecture}\")\n",
    "    nn_arch.train(X_train, y_train_onehot, epochs = 1000, mini_batch_size = 32, lr = 0.01)\n",
    "    print(f\"Trained Architecture: {architecture}\")\n",
    "    y_pred = nn_arch.predict(X_test)\n",
    "    y_pred_new = np.argmax(y_pred, axis = 1)\n",
    "    precision = precision_score(y_test_new, y_pred_new, average=None)\n",
    "    recall = recall_score(y_test_new, y_pred_new, average=None)\n",
    "    f1 = f1_score(y_test_new, y_pred_new, average=None)\n",
    "    accuracy = np.sum(y_pred_new == y_test_new) / len(y_test_new)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    part_c_file.write(f\"Architecture: {architecture}\\nTest Data\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\nAccuracy: {accuracy}\\n\")\n",
    "    y_train_pred = nn_arch.predict(X_train)\n",
    "    y_train_pred_new = np.argmax(y_train_pred, axis = 1)\n",
    "    precision = precision_score(y_train, y_train_pred_new, average=None)\n",
    "    recall = recall_score(y_train, y_train_pred_new, average=None)\n",
    "    f1 = f1_score(y_train, y_train_pred_new, average=None)\n",
    "    accuracy = accuracy_score(y_train, y_train_pred_new)\n",
    "    print(f\"Train Accuracy: {accuracy}\")\n",
    "    part_c_file.write(f\"Training Data\\nPrecision: {precision}\\nTrain Recall: {recall}\\nTrain F1 Score: {f1}\\nTrain Accuracy: {accuracy}\\n\\n\")\n",
    "part_c_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_c_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Architecture: [512]\n",
      "Epoch = 0\n",
      "Epoch = 10\n",
      "Epoch = 20\n",
      "Epoch = 30\n",
      "Epoch = 40\n",
      "Epoch = 50\n",
      "Epoch = 60\n",
      "Epoch = 70\n",
      "Epoch = 80\n",
      "Epoch = 90\n",
      "Epoch = 100\n",
      "Epoch = 110\n",
      "Epoch = 120\n",
      "Epoch = 130\n",
      "Epoch = 140\n",
      "Epoch = 150\n",
      "Epoch = 160\n",
      "Epoch = 170\n",
      "Epoch = 180\n",
      "Epoch = 190\n",
      "Epoch = 200\n",
      "Epoch = 210\n",
      "Epoch = 220\n",
      "Epoch = 230\n",
      "Epoch = 240\n",
      "Epoch = 250\n",
      "Epoch = 260\n",
      "Epoch = 270\n",
      "Epoch = 280\n",
      "Epoch = 290\n",
      "Epoch = 300\n",
      "Epoch = 310\n",
      "Epoch = 320\n",
      "Epoch = 330\n",
      "Epoch = 340\n",
      "Epoch = 350\n",
      "Epoch = 360\n",
      "Epoch = 370\n",
      "Epoch = 380\n",
      "Epoch = 390\n",
      "Epoch = 400\n",
      "Epoch = 410\n",
      "Epoch = 420\n",
      "Epoch = 430\n",
      "Epoch = 440\n",
      "Epoch = 450\n",
      "Epoch = 460\n",
      "Epoch = 470\n",
      "Epoch = 480\n",
      "Epoch = 490\n",
      "Epoch = 500\n",
      "Epoch = 510\n",
      "Epoch = 520\n",
      "Epoch = 530\n",
      "Epoch = 540\n",
      "Epoch = 550\n",
      "Epoch = 560\n",
      "Epoch = 570\n",
      "Epoch = 580\n",
      "Epoch = 590\n",
      "Epoch = 600\n",
      "Epoch = 610\n",
      "Epoch = 620\n",
      "Epoch = 630\n",
      "Epoch = 640\n",
      "Epoch = 650\n",
      "Epoch = 660\n",
      "Epoch = 670\n",
      "Epoch = 680\n",
      "Epoch = 690\n",
      "Epoch = 700\n",
      "Epoch = 710\n",
      "Epoch = 720\n",
      "Epoch = 730\n",
      "Epoch = 740\n",
      "Epoch = 750\n",
      "Epoch = 760\n",
      "Epoch = 770\n",
      "Epoch = 780\n",
      "Epoch = 790\n",
      "Epoch = 800\n",
      "Epoch = 810\n",
      "Epoch = 820\n",
      "Epoch = 830\n",
      "Epoch = 840\n",
      "Epoch = 850\n",
      "Epoch = 860\n",
      "Epoch = 870\n",
      "Epoch = 880\n",
      "Epoch = 890\n",
      "Epoch = 900\n",
      "Epoch = 910\n",
      "Epoch = 920\n",
      "Epoch = 930\n",
      "Epoch = 940\n",
      "Epoch = 950\n",
      "Epoch = 960\n",
      "Epoch = 970\n",
      "Epoch = 980\n",
      "Epoch = 990\n",
      "Trained Architecture: [512]\n",
      "Accuracy: 0.622\n",
      "Train Accuracy: 0.6643\n",
      "Starting Architecture: [512, 256]\n",
      "Epoch = 0\n",
      "Epoch = 10\n",
      "Epoch = 20\n",
      "Epoch = 30\n",
      "Epoch = 40\n",
      "Epoch = 50\n",
      "Epoch = 60\n",
      "Epoch = 70\n",
      "Epoch = 80\n",
      "Epoch = 90\n",
      "Epoch = 100\n",
      "Epoch = 110\n",
      "Epoch = 120\n",
      "Epoch = 130\n",
      "Epoch = 140\n",
      "Epoch = 150\n",
      "Epoch = 160\n",
      "Epoch = 170\n",
      "Epoch = 180\n",
      "Epoch = 190\n",
      "Epoch = 200\n",
      "Epoch = 210\n",
      "Epoch = 220\n",
      "Epoch = 230\n",
      "Epoch = 240\n",
      "Epoch = 250\n",
      "Epoch = 260\n",
      "Epoch = 270\n",
      "Epoch = 280\n",
      "Epoch = 290\n",
      "Epoch = 300\n",
      "Epoch = 310\n",
      "Epoch = 320\n",
      "Epoch = 330\n",
      "Epoch = 340\n",
      "Epoch = 350\n",
      "Epoch = 360\n",
      "Epoch = 370\n",
      "Epoch = 380\n",
      "Epoch = 390\n",
      "Epoch = 400\n",
      "Epoch = 410\n",
      "Epoch = 420\n",
      "Epoch = 430\n",
      "Epoch = 440\n",
      "Epoch = 450\n",
      "Epoch = 460\n",
      "Epoch = 470\n",
      "Epoch = 480\n",
      "Epoch = 490\n",
      "Epoch = 500\n",
      "Epoch = 510\n",
      "Epoch = 520\n",
      "Epoch = 530\n",
      "Epoch = 540\n",
      "Epoch = 550\n",
      "Epoch = 560\n",
      "Epoch = 570\n",
      "Epoch = 580\n",
      "Epoch = 590\n",
      "Epoch = 600\n",
      "Epoch = 610\n",
      "Epoch = 620\n",
      "Epoch = 630\n",
      "Epoch = 640\n",
      "Epoch = 650\n",
      "Epoch = 660\n",
      "Epoch = 670\n",
      "Epoch = 680\n",
      "Epoch = 690\n",
      "Epoch = 700\n",
      "Epoch = 710\n",
      "Epoch = 720\n",
      "Epoch = 730\n",
      "Epoch = 740\n",
      "Epoch = 750\n",
      "Epoch = 760\n",
      "Epoch = 770\n",
      "Epoch = 780\n",
      "Epoch = 790\n",
      "Epoch = 800\n",
      "Epoch = 810\n",
      "Epoch = 820\n",
      "Epoch = 830\n",
      "Epoch = 840\n",
      "Epoch = 850\n",
      "Epoch = 860\n",
      "Epoch = 870\n",
      "Epoch = 880\n",
      "Epoch = 890\n",
      "Epoch = 900\n",
      "Epoch = 910\n",
      "Epoch = 920\n",
      "Epoch = 930\n",
      "Epoch = 940\n",
      "Epoch = 950\n",
      "Epoch = 960\n",
      "Epoch = 970\n",
      "Epoch = 980\n",
      "Epoch = 990\n",
      "Trained Architecture: [512, 256]\n",
      "Accuracy: 0.651\n",
      "Train Accuracy: 0.6917\n",
      "Starting Architecture: [512, 256, 128]\n",
      "Epoch = 0\n",
      "Epoch = 10\n",
      "Epoch = 20\n",
      "Epoch = 30\n",
      "Epoch = 40\n",
      "Epoch = 50\n",
      "Epoch = 60\n",
      "Epoch = 70\n",
      "Epoch = 80\n",
      "Epoch = 90\n",
      "Epoch = 100\n",
      "Epoch = 110\n",
      "Epoch = 120\n",
      "Epoch = 130\n",
      "Epoch = 140\n",
      "Epoch = 150\n",
      "Epoch = 160\n",
      "Epoch = 170\n",
      "Epoch = 180\n",
      "Epoch = 190\n",
      "Epoch = 200\n",
      "Epoch = 210\n",
      "Epoch = 220\n",
      "Epoch = 230\n",
      "Epoch = 240\n",
      "Epoch = 250\n",
      "Epoch = 260\n",
      "Epoch = 270\n",
      "Epoch = 280\n",
      "Epoch = 290\n",
      "Epoch = 300\n",
      "Epoch = 310\n",
      "Epoch = 320\n",
      "Epoch = 330\n",
      "Epoch = 340\n",
      "Epoch = 350\n",
      "Epoch = 360\n",
      "Epoch = 370\n",
      "Epoch = 380\n",
      "Epoch = 390\n",
      "Epoch = 400\n",
      "Epoch = 410\n",
      "Epoch = 420\n",
      "Epoch = 430\n",
      "Epoch = 440\n",
      "Epoch = 450\n",
      "Epoch = 460\n",
      "Epoch = 470\n",
      "Epoch = 480\n",
      "Epoch = 490\n",
      "Epoch = 500\n",
      "Epoch = 510\n",
      "Epoch = 520\n",
      "Epoch = 530\n",
      "Epoch = 540\n",
      "Epoch = 550\n",
      "Epoch = 560\n",
      "Epoch = 570\n",
      "Epoch = 580\n",
      "Epoch = 590\n",
      "Epoch = 600\n",
      "Epoch = 610\n",
      "Epoch = 620\n",
      "Epoch = 630\n",
      "Epoch = 640\n",
      "Epoch = 650\n",
      "Epoch = 660\n",
      "Epoch = 670\n",
      "Epoch = 680\n",
      "Epoch = 690\n",
      "Epoch = 700\n",
      "Epoch = 710\n",
      "Epoch = 720\n",
      "Epoch = 730\n",
      "Epoch = 740\n",
      "Epoch = 750\n",
      "Epoch = 760\n",
      "Epoch = 770\n",
      "Epoch = 780\n",
      "Epoch = 790\n",
      "Epoch = 800\n",
      "Epoch = 810\n",
      "Epoch = 820\n",
      "Epoch = 830\n",
      "Epoch = 840\n",
      "Epoch = 850\n",
      "Epoch = 860\n",
      "Epoch = 870\n",
      "Epoch = 880\n",
      "Epoch = 890\n",
      "Epoch = 900\n",
      "Epoch = 910\n",
      "Epoch = 920\n",
      "Epoch = 930\n",
      "Epoch = 940\n",
      "Epoch = 950\n",
      "Epoch = 960\n",
      "Epoch = 970\n",
      "Epoch = 980\n",
      "Epoch = 990\n",
      "Trained Architecture: [512, 256, 128]\n",
      "Accuracy: 0.658\n",
      "Train Accuracy: 0.7009\n",
      "Starting Architecture: [512, 256, 128, 64]\n",
      "Epoch = 0\n",
      "Epoch = 10\n",
      "Epoch = 20\n",
      "Epoch = 30\n",
      "Epoch = 40\n",
      "Epoch = 50\n",
      "Epoch = 60\n",
      "Epoch = 70\n",
      "Epoch = 80\n",
      "Epoch = 90\n",
      "Epoch = 100\n",
      "Epoch = 110\n",
      "Epoch = 120\n",
      "Epoch = 130\n",
      "Epoch = 140\n",
      "Epoch = 150\n",
      "Epoch = 160\n",
      "Epoch = 170\n",
      "Epoch = 180\n",
      "Epoch = 190\n",
      "Epoch = 200\n",
      "Epoch = 210\n",
      "Epoch = 220\n",
      "Epoch = 230\n",
      "Epoch = 240\n",
      "Epoch = 250\n",
      "Epoch = 260\n",
      "Epoch = 270\n",
      "Epoch = 280\n",
      "Epoch = 290\n",
      "Epoch = 300\n",
      "Epoch = 310\n",
      "Epoch = 320\n",
      "Epoch = 330\n",
      "Epoch = 340\n",
      "Epoch = 350\n",
      "Epoch = 360\n",
      "Epoch = 370\n",
      "Epoch = 380\n",
      "Epoch = 390\n",
      "Epoch = 400\n",
      "Epoch = 410\n",
      "Epoch = 420\n",
      "Epoch = 430\n",
      "Epoch = 440\n",
      "Epoch = 450\n",
      "Epoch = 460\n",
      "Epoch = 470\n",
      "Epoch = 480\n",
      "Epoch = 490\n",
      "Epoch = 500\n",
      "Epoch = 510\n",
      "Epoch = 520\n",
      "Epoch = 530\n",
      "Epoch = 540\n",
      "Epoch = 550\n",
      "Epoch = 560\n",
      "Epoch = 570\n",
      "Epoch = 580\n",
      "Epoch = 590\n",
      "Epoch = 600\n",
      "Epoch = 610\n",
      "Epoch = 620\n",
      "Epoch = 630\n",
      "Epoch = 640\n",
      "Epoch = 650\n",
      "Epoch = 660\n",
      "Epoch = 670\n",
      "Epoch = 680\n",
      "Epoch = 690\n",
      "Epoch = 700\n",
      "Epoch = 710\n",
      "Epoch = 720\n",
      "Epoch = 730\n",
      "Epoch = 740\n",
      "Epoch = 750\n",
      "Epoch = 760\n",
      "Epoch = 770\n",
      "Epoch = 780\n",
      "Epoch = 790\n",
      "Epoch = 800\n",
      "Epoch = 810\n",
      "Epoch = 820\n",
      "Epoch = 830\n",
      "Epoch = 840\n",
      "Epoch = 850\n",
      "Epoch = 860\n",
      "Epoch = 870\n",
      "Epoch = 880\n",
      "Epoch = 890\n",
      "Epoch = 900\n",
      "Epoch = 910\n",
      "Epoch = 920\n",
      "Epoch = 930\n",
      "Epoch = 940\n",
      "Epoch = 950\n",
      "Epoch = 960\n",
      "Epoch = 970\n",
      "Epoch = 980\n",
      "Epoch = 990\n",
      "Trained Architecture: [512, 256, 128, 64]\n",
      "Accuracy: 0.681\n",
      "Train Accuracy: 0.731\n"
     ]
    }
   ],
   "source": [
    "# Adaptive LR and Sigmoid\n",
    "part_d_file = open('part_d.txt', 'w')\n",
    "architectures = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]\n",
    "\n",
    "for architecture in architectures:\n",
    "    nn_arch = NeuralNetwork(1024, 5, architecture, 0, True)\n",
    "    print(f\"Starting Architecture: {architecture}\")\n",
    "    nn_arch.train(X_train, y_train_onehot, epochs = 1000, mini_batch_size = 32, lr = 0.01)\n",
    "    print(f\"Trained Architecture: {architecture}\")\n",
    "    y_pred = nn_arch.predict(X_test)\n",
    "    y_pred_new = np.argmax(y_pred, axis = 1)\n",
    "    precision = precision_score(y_test_new, y_pred_new, average=None)\n",
    "    recall = recall_score(y_test_new, y_pred_new, average=None)\n",
    "    f1 = f1_score(y_test_new, y_pred_new, average=None)\n",
    "    accuracy = np.sum(y_pred_new == y_test_new) / len(y_test_new)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    part_d_file.write(f\"Architecture: {architecture}\\nTest Data\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\nAccuracy: {accuracy}\\n\")\n",
    "    y_train_pred = nn_arch.predict(X_train)\n",
    "    y_train_pred_new = np.argmax(y_train_pred, axis = 1)\n",
    "    precision = precision_score(y_train_new, y_train_pred_new, average=None)\n",
    "    recall = recall_score(y_train_new, y_train_pred_new, average=None)\n",
    "    f1 = f1_score(y_train_new, y_train_pred_new, average=None)\n",
    "    accuracy = accuracy_score(y_train_new, y_train_pred_new)\n",
    "    print(f\"Train Accuracy: {accuracy}\")\n",
    "    part_d_file.write(f\"Training Data\\nPrecision: {precision}\\nTrain Recall: {recall}\\nTrain F1 Score: {f1}\\nTrain Accuracy: {accuracy}\\n\\n\")\n",
    "part_d_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Architecture: [512]\n",
      "Epoch = 0\n",
      "Epoch = 10\n",
      "Epoch = 20\n",
      "Epoch = 30\n",
      "Epoch = 40\n",
      "Epoch = 50\n",
      "Epoch = 60\n",
      "Epoch = 70\n",
      "Epoch = 80\n",
      "Epoch = 90\n",
      "Epoch = 100\n",
      "Epoch = 110\n",
      "Epoch = 120\n",
      "Epoch = 130\n",
      "Epoch = 140\n",
      "Epoch = 150\n",
      "Epoch = 160\n",
      "Epoch = 170\n",
      "Epoch = 180\n",
      "Epoch = 190\n",
      "Epoch = 200\n",
      "Epoch = 210\n",
      "Epoch = 220\n",
      "Epoch = 230\n",
      "Epoch = 240\n",
      "Epoch = 250\n",
      "Epoch = 260\n",
      "Epoch = 270\n",
      "Epoch = 280\n",
      "Epoch = 290\n",
      "Epoch = 300\n",
      "Epoch = 310\n",
      "Epoch = 320\n",
      "Epoch = 330\n",
      "Epoch = 340\n",
      "Epoch = 350\n",
      "Epoch = 360\n",
      "Epoch = 370\n",
      "Epoch = 380\n",
      "Epoch = 390\n",
      "Epoch = 400\n",
      "Epoch = 410\n",
      "Epoch = 420\n",
      "Epoch = 430\n",
      "Epoch = 440\n",
      "Epoch = 450\n",
      "Epoch = 460\n",
      "Epoch = 470\n",
      "Epoch = 480\n",
      "Epoch = 490\n",
      "Epoch = 500\n",
      "Epoch = 510\n",
      "Epoch = 520\n",
      "Epoch = 530\n",
      "Epoch = 540\n",
      "Epoch = 550\n",
      "Epoch = 560\n",
      "Epoch = 570\n",
      "Epoch = 580\n",
      "Epoch = 590\n",
      "Epoch = 600\n",
      "Epoch = 610\n",
      "Epoch = 620\n",
      "Epoch = 630\n",
      "Epoch = 640\n",
      "Epoch = 650\n",
      "Epoch = 660\n",
      "Epoch = 670\n",
      "Epoch = 680\n",
      "Epoch = 690\n",
      "Epoch = 700\n",
      "Epoch = 710\n",
      "Epoch = 720\n",
      "Epoch = 730\n",
      "Epoch = 740\n",
      "Epoch = 750\n",
      "Epoch = 760\n",
      "Epoch = 770\n",
      "Epoch = 780\n",
      "Epoch = 790\n",
      "Epoch = 800\n",
      "Epoch = 810\n",
      "Epoch = 820\n",
      "Epoch = 830\n",
      "Epoch = 840\n",
      "Epoch = 850\n",
      "Epoch = 860\n",
      "Epoch = 870\n",
      "Epoch = 880\n",
      "Epoch = 890\n",
      "Epoch = 900\n",
      "Epoch = 910\n",
      "Epoch = 920\n",
      "Epoch = 930\n",
      "Epoch = 940\n",
      "Epoch = 950\n",
      "Epoch = 960\n",
      "Epoch = 970\n",
      "Epoch = 980\n",
      "Epoch = 990\n",
      "Trained Architecture: [512]\n",
      "Accuracy: 0.633\n",
      "Train Accuracy: 0.665\n",
      "Starting Architecture: [512, 256]\n",
      "Epoch = 0\n",
      "Epoch = 10\n",
      "Epoch = 20\n",
      "Epoch = 30\n",
      "Epoch = 40\n",
      "Epoch = 50\n",
      "Epoch = 60\n",
      "Epoch = 70\n",
      "Epoch = 80\n",
      "Epoch = 90\n",
      "Epoch = 100\n",
      "Epoch = 110\n",
      "Epoch = 120\n",
      "Epoch = 130\n",
      "Epoch = 140\n",
      "Epoch = 150\n",
      "Epoch = 160\n",
      "Epoch = 170\n",
      "Epoch = 180\n",
      "Epoch = 190\n",
      "Epoch = 200\n",
      "Epoch = 210\n",
      "Epoch = 220\n",
      "Epoch = 230\n",
      "Epoch = 240\n",
      "Epoch = 250\n",
      "Epoch = 260\n",
      "Epoch = 270\n",
      "Epoch = 280\n",
      "Epoch = 290\n",
      "Epoch = 300\n",
      "Epoch = 310\n",
      "Epoch = 320\n",
      "Epoch = 330\n",
      "Epoch = 340\n",
      "Epoch = 350\n",
      "Epoch = 360\n",
      "Epoch = 370\n",
      "Epoch = 380\n",
      "Epoch = 390\n",
      "Epoch = 400\n",
      "Epoch = 410\n",
      "Epoch = 420\n",
      "Epoch = 430\n",
      "Epoch = 440\n",
      "Epoch = 450\n",
      "Epoch = 460\n",
      "Epoch = 470\n",
      "Epoch = 480\n",
      "Epoch = 490\n",
      "Epoch = 500\n",
      "Epoch = 510\n",
      "Epoch = 520\n",
      "Epoch = 530\n",
      "Epoch = 540\n",
      "Epoch = 550\n",
      "Epoch = 560\n",
      "Epoch = 570\n",
      "Epoch = 580\n",
      "Epoch = 590\n",
      "Epoch = 600\n",
      "Epoch = 610\n",
      "Epoch = 620\n",
      "Epoch = 630\n",
      "Epoch = 640\n",
      "Epoch = 650\n",
      "Epoch = 660\n",
      "Epoch = 670\n",
      "Epoch = 680\n",
      "Epoch = 690\n",
      "Epoch = 700\n",
      "Epoch = 710\n",
      "Epoch = 720\n",
      "Epoch = 730\n",
      "Epoch = 740\n",
      "Epoch = 750\n",
      "Epoch = 760\n",
      "Epoch = 770\n",
      "Epoch = 780\n",
      "Epoch = 790\n",
      "Epoch = 800\n",
      "Epoch = 810\n",
      "Epoch = 820\n",
      "Epoch = 830\n",
      "Epoch = 840\n",
      "Epoch = 850\n",
      "Epoch = 860\n",
      "Epoch = 870\n",
      "Epoch = 880\n",
      "Epoch = 890\n",
      "Epoch = 900\n",
      "Epoch = 910\n",
      "Epoch = 920\n",
      "Epoch = 930\n",
      "Epoch = 940\n",
      "Epoch = 950\n",
      "Epoch = 960\n",
      "Epoch = 970\n",
      "Epoch = 980\n",
      "Epoch = 990\n",
      "Trained Architecture: [512, 256]\n",
      "Accuracy: 0.656\n",
      "Train Accuracy: 0.6803\n",
      "Starting Architecture: [512, 256, 128]\n",
      "Epoch = 0\n",
      "Epoch = 10\n",
      "Epoch = 20\n",
      "Epoch = 30\n",
      "Epoch = 40\n",
      "Epoch = 50\n",
      "Epoch = 60\n",
      "Epoch = 70\n",
      "Epoch = 80\n",
      "Epoch = 90\n",
      "Epoch = 100\n",
      "Epoch = 110\n",
      "Epoch = 120\n",
      "Epoch = 130\n",
      "Epoch = 140\n",
      "Epoch = 150\n",
      "Epoch = 160\n",
      "Epoch = 170\n",
      "Epoch = 180\n",
      "Epoch = 190\n",
      "Epoch = 200\n",
      "Epoch = 210\n",
      "Epoch = 220\n",
      "Epoch = 230\n",
      "Epoch = 240\n",
      "Epoch = 250\n",
      "Epoch = 260\n",
      "Epoch = 270\n",
      "Epoch = 280\n",
      "Epoch = 290\n",
      "Epoch = 300\n",
      "Epoch = 310\n",
      "Epoch = 320\n",
      "Epoch = 330\n",
      "Epoch = 340\n",
      "Epoch = 350\n",
      "Epoch = 360\n",
      "Epoch = 370\n",
      "Epoch = 380\n",
      "Epoch = 390\n",
      "Epoch = 400\n",
      "Epoch = 410\n",
      "Epoch = 420\n",
      "Epoch = 430\n",
      "Epoch = 440\n",
      "Epoch = 450\n",
      "Epoch = 460\n",
      "Epoch = 470\n",
      "Epoch = 480\n",
      "Epoch = 490\n",
      "Epoch = 500\n",
      "Epoch = 510\n",
      "Epoch = 520\n",
      "Epoch = 530\n",
      "Epoch = 540\n",
      "Epoch = 550\n",
      "Epoch = 560\n",
      "Epoch = 570\n",
      "Epoch = 580\n",
      "Epoch = 590\n",
      "Epoch = 600\n",
      "Epoch = 610\n",
      "Epoch = 620\n",
      "Epoch = 630\n",
      "Epoch = 640\n",
      "Epoch = 650\n",
      "Epoch = 660\n",
      "Epoch = 670\n",
      "Epoch = 680\n",
      "Epoch = 690\n",
      "Epoch = 700\n",
      "Epoch = 710\n",
      "Epoch = 720\n",
      "Epoch = 730\n",
      "Epoch = 740\n",
      "Epoch = 750\n",
      "Epoch = 760\n",
      "Epoch = 770\n",
      "Epoch = 780\n",
      "Epoch = 790\n",
      "Epoch = 800\n",
      "Epoch = 810\n",
      "Epoch = 820\n",
      "Epoch = 830\n",
      "Epoch = 840\n",
      "Epoch = 850\n",
      "Epoch = 860\n",
      "Epoch = 870\n",
      "Epoch = 880\n",
      "Epoch = 890\n",
      "Epoch = 900\n",
      "Epoch = 910\n",
      "Epoch = 920\n",
      "Epoch = 930\n",
      "Epoch = 940\n",
      "Epoch = 950\n",
      "Epoch = 960\n",
      "Epoch = 970\n",
      "Epoch = 980\n",
      "Epoch = 990\n",
      "Trained Architecture: [512, 256, 128]\n",
      "Accuracy: 0.678\n",
      "Train Accuracy: 0.7137\n",
      "Starting Architecture: [512, 256, 128, 64]\n",
      "Epoch = 0\n",
      "Epoch = 10\n",
      "Epoch = 20\n",
      "Epoch = 30\n",
      "Epoch = 40\n",
      "Epoch = 50\n",
      "Epoch = 60\n",
      "Epoch = 70\n",
      "Epoch = 80\n",
      "Epoch = 90\n",
      "Epoch = 100\n",
      "Epoch = 110\n",
      "Epoch = 120\n",
      "Epoch = 130\n",
      "Epoch = 140\n",
      "Epoch = 150\n",
      "Epoch = 160\n",
      "Epoch = 170\n",
      "Epoch = 180\n",
      "Epoch = 190\n",
      "Epoch = 200\n",
      "Epoch = 210\n",
      "Epoch = 220\n",
      "Epoch = 230\n",
      "Epoch = 240\n",
      "Epoch = 250\n",
      "Epoch = 260\n",
      "Epoch = 270\n",
      "Epoch = 280\n",
      "Epoch = 290\n",
      "Epoch = 300\n",
      "Epoch = 310\n",
      "Epoch = 320\n",
      "Epoch = 330\n",
      "Epoch = 340\n",
      "Epoch = 350\n",
      "Epoch = 360\n",
      "Epoch = 370\n",
      "Epoch = 380\n",
      "Epoch = 390\n",
      "Epoch = 400\n",
      "Epoch = 410\n",
      "Epoch = 420\n",
      "Epoch = 430\n",
      "Epoch = 440\n",
      "Epoch = 450\n",
      "Epoch = 460\n",
      "Epoch = 470\n",
      "Epoch = 480\n",
      "Epoch = 490\n",
      "Epoch = 500\n",
      "Epoch = 510\n",
      "Epoch = 520\n",
      "Epoch = 530\n",
      "Epoch = 540\n",
      "Epoch = 550\n",
      "Epoch = 560\n",
      "Epoch = 570\n",
      "Epoch = 580\n",
      "Epoch = 590\n",
      "Epoch = 600\n",
      "Epoch = 610\n",
      "Epoch = 620\n",
      "Epoch = 630\n",
      "Epoch = 640\n",
      "Epoch = 650\n",
      "Epoch = 660\n",
      "Epoch = 670\n",
      "Epoch = 680\n",
      "Epoch = 690\n",
      "Epoch = 700\n",
      "Epoch = 710\n",
      "Epoch = 720\n",
      "Epoch = 730\n",
      "Epoch = 740\n",
      "Epoch = 750\n",
      "Epoch = 760\n",
      "Epoch = 770\n",
      "Epoch = 780\n",
      "Epoch = 790\n",
      "Epoch = 800\n",
      "Epoch = 810\n",
      "Epoch = 820\n",
      "Epoch = 830\n",
      "Epoch = 840\n",
      "Epoch = 850\n",
      "Epoch = 860\n",
      "Epoch = 870\n",
      "Epoch = 880\n",
      "Epoch = 890\n",
      "Epoch = 900\n",
      "Epoch = 910\n",
      "Epoch = 920\n",
      "Epoch = 930\n",
      "Epoch = 940\n",
      "Epoch = 950\n",
      "Epoch = 960\n",
      "Epoch = 970\n",
      "Epoch = 980\n",
      "Epoch = 990\n",
      "Trained Architecture: [512, 256, 128, 64]\n",
      "Accuracy: 0.68\n",
      "Train Accuracy: 0.7139\n"
     ]
    }
   ],
   "source": [
    "# Adaptive LR and ReLu \n",
    "part_e_file = open('part_e.txt', 'w')\n",
    "architectures = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]\n",
    "\n",
    "for architecture in architectures:\n",
    "    nn_arch = NeuralNetwork(1024, 5, architecture, 0, True)\n",
    "    print(f\"Starting Architecture: {architecture}\")\n",
    "    nn_arch.train(X_train, y_train_onehot, epochs = 1000, mini_batch_size = 32, lr = 0.01)\n",
    "    print(f\"Trained Architecture: {architecture}\")\n",
    "    y_pred = nn_arch.predict(X_test)\n",
    "    y_pred_new = np.argmax(y_pred, axis = 1)\n",
    "    precision = precision_score(y_test_new, y_pred_new, average=None)\n",
    "    recall = recall_score(y_test_new, y_pred_new, average=None)\n",
    "    f1 = f1_score(y_test_new, y_pred_new, average=None)\n",
    "    accuracy = np.sum(y_pred_new == y_test_new) / len(y_test_new)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    part_e_file.write(f\"Architecture: {architecture}\\nTest Data\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\nAccuracy: {accuracy}\\n\")\n",
    "    y_train_pred = nn_arch.predict(X_train)\n",
    "    y_train_pred_new = np.argmax(y_train_pred, axis = 1)\n",
    "    precision = precision_score(y_train_new, y_train_pred_new, average=None)\n",
    "    recall = recall_score(y_train_new, y_train_pred_new, average=None)\n",
    "    f1 = f1_score(y_train_new, y_train_pred_new, average=None)\n",
    "    accuracy = accuracy_score(y_train_new, y_train_pred_new)\n",
    "    print(f\"Train Accuracy: {accuracy}\")\n",
    "    part_e_file.write(f\"Training Data\\nPrecision: {precision}\\nTrain Recall: {recall}\\nTrain F1 Score: {f1}\\nTrain Accuracy: {accuracy}\\n\\n\")\n",
    "part_e_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
