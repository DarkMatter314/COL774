{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is started code for part b and c. \n",
    "Using this code is OPTIONAL and you may write code from scratch if you want\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = None \n",
    "\n",
    "def get_np_array(file_name):\n",
    "    global label_encoder\n",
    "    data = pd.read_csv(file_name)\n",
    "    \n",
    "    need_label_encoding = ['team','host','opp','month', 'day_match']\n",
    "    if(label_encoder is None):\n",
    "        label_encoder = OneHotEncoder(sparse_output = False)\n",
    "        label_encoder.fit(data[need_label_encoding])\n",
    "    data_1 = pd.DataFrame(label_encoder.transform(data[need_label_encoding]), columns = label_encoder.get_feature_names_out())\n",
    "    \n",
    "    #merge the two dataframes\n",
    "    dont_need_label_encoding =  [\"year\",\"toss\",\"bat_first\",\"format\" ,\"fow\",\"score\" ,\"rpo\" ,\"result\"]\n",
    "    data_2 = data[dont_need_label_encoding]\n",
    "    final_data = pd.concat([data_1, data_2], axis=1)\n",
    "    \n",
    "    X = final_data.iloc[:,:-1]\n",
    "    y = final_data.iloc[:,-1:]\n",
    "    return X.to_numpy(), y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTNode:\n",
    "\n",
    "    def __init__(self, depth, is_leaf = False, value = 0, column = None, split_values = [], thresh = 0.0, type = 0):\n",
    "        #to split on column\n",
    "        self.depth = depth\n",
    "\n",
    "        #add children afterwards\n",
    "        self.children = []\n",
    "\n",
    "        #if leaf then also need value\n",
    "        self.is_leaf = is_leaf\n",
    "        if(self.is_leaf):\n",
    "            self.value = value\n",
    "        \n",
    "        if(not self.is_leaf):\n",
    "            self.value = value\n",
    "            self.column = column\n",
    "            # split_values is a list denoting the values on which to split on children\n",
    "            self.split_values = split_values\n",
    "            self.thresh = thresh\n",
    "            self.type = type\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "\n",
    "    def get_children(self, X):\n",
    "        '''\n",
    "        Args:\n",
    "            X: A single example np array [num_features]\n",
    "        Returns:\n",
    "            child: A DTNode\n",
    "        '''\n",
    "        if(self.type == 0):\n",
    "            for i in range(len(self.split_values)):\n",
    "                if(X[self.column] == self.split_values[i]):\n",
    "                    return self.children[i]\n",
    "            return None\n",
    "        else:\n",
    "            if(X[self.column] <= self.thresh):\n",
    "                return self.children[0]\n",
    "            else:\n",
    "                return self.children[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTTree:\n",
    "\n",
    "    def __init__(self):\n",
    "        #Tree root should be DTNode\n",
    "        self.root = None\n",
    "        self.train_accuracy = []\n",
    "        self.val_accuracy = []\n",
    "        self.test_accuracy = []\n",
    "\n",
    "    def entropy(self, y):\n",
    "        '''\n",
    "        Return entropy of y\n",
    "        Args:\n",
    "            y: numpy array of shape [num_samples, 1]\n",
    "        Returns:\n",
    "            entropy: scalar value\n",
    "        '''\n",
    "        y_zeros = np.count_nonzero(y == 0)\n",
    "        total_y = y.shape[0]\n",
    "        if(y_zeros == total_y or y_zeros == 0):\n",
    "            return 0\n",
    "        else:\n",
    "            return -y_zeros/total_y*np.log2(y_zeros/total_y) - (total_y-y_zeros)/total_y*np.log2((total_y-y_zeros)/total_y)\n",
    "        \n",
    "    def get_best_attribute(self, X, y, types):\n",
    "        entropy_i = self.entropy(y)\n",
    "        max_gain = 0\n",
    "        best_attribute = 0\n",
    "        for i in range(X.shape[1]):\n",
    "            new_entropy = 0\n",
    "            if(types[i] == 'cont'):\n",
    "                unique_values = np.unique(X[:,i])\n",
    "                unique_values = np.sort(unique_values)\n",
    "                # set threshold to median of unique values\n",
    "                thresh = np.median(unique_values)\n",
    "                lower_indices = np.where(X[:,i] <= thresh)\n",
    "                lower_total = y[lower_indices].shape[0]\n",
    "                upper_indices = np.where(X[:,i] > thresh)\n",
    "                upper_total = y[upper_indices].shape[0]\n",
    "                new_entropy = lower_total/X.shape[0]*self.entropy(y[lower_indices]) + upper_total/X.shape[0]*self.entropy(y[upper_indices])\n",
    "            else:\n",
    "                unique_values = np.unique(X[:,i])\n",
    "                for j in range(unique_values.shape[0]):\n",
    "                    indices = np.where(X[:,i] == unique_values[j])\n",
    "                    new_entropy += indices[0].shape[0]/X.shape[0]*self.entropy(y[indices])\n",
    "            new_gain = entropy_i - new_entropy\n",
    "            if(new_gain > max_gain):\n",
    "                max_gain = new_gain\n",
    "                best_attribute = i\n",
    "        return best_attribute\n",
    "\n",
    "    def train(self, X, y, types, depth, max_depth):\n",
    "        ''' \n",
    "        Return a node of class DTNode\n",
    "        '''   \n",
    "        y_zeros = np.count_nonzero(y == 0)\n",
    "        total_y = y.shape[0]\n",
    "        if(y_zeros == total_y):\n",
    "            return DTNode(depth, True, 0, None, [], 0, 0)\n",
    "        if(y_zeros == 0):\n",
    "            return DTNode(depth, True, 1, None, [], 0, 0)\n",
    "        if(depth == max_depth):\n",
    "            if(y_zeros >= total_y/2):\n",
    "                return DTNode(depth, True, 0, None, [], 0, 0)\n",
    "            else:\n",
    "                return DTNode(depth, True, 1, None, [], 0, 0)\n",
    "        best_attribute = self.get_best_attribute(X, y, types)\n",
    "        if(types[best_attribute] == 'cont'):\n",
    "            unique_values = np.unique(X[:,best_attribute])\n",
    "            unique_values = np.sort(unique_values)\n",
    "            # set threshold to median of unique values\n",
    "            thresh = np.median(unique_values)\n",
    "            lower_indices = np.where(X[:,best_attribute] <= thresh)\n",
    "            upper_indices = np.where(X[:,best_attribute] > thresh)\n",
    "            y_zeros = np.count_nonzero(y[lower_indices] == 0)\n",
    "            total_y = y[lower_indices].shape[0]\n",
    "            value = 0 if y_zeros >= total_y/2 else 1\n",
    "            node = DTNode(depth, False, value, best_attribute, [], float(thresh), 1)\n",
    "            node.add_child(self.train(X[lower_indices], y[lower_indices], types, depth+1, max_depth))\n",
    "            node.add_child(self.train(X[upper_indices], y[upper_indices], types, depth+1, max_depth))\n",
    "            return node\n",
    "        else:\n",
    "            unique_values = np.unique(X[:,best_attribute])\n",
    "            y_zeros = np.count_nonzero(y == 0)\n",
    "            total_y = y.shape[0]\n",
    "            value = 0 if y_zeros >= total_y/2 else 1\n",
    "            node = DTNode(depth, False, value, best_attribute, unique_values, 0, 0)\n",
    "            for i in range(unique_values.shape[0]):\n",
    "                indices = np.where(X[:,best_attribute] == unique_values[i])\n",
    "                node.add_child(self.train(X[indices], y[indices], types, depth+1, max_depth))\n",
    "            return node\n",
    "        \n",
    "\n",
    "    def fit(self, X, y, types, max_depth = 10):\n",
    "        '''\n",
    "        Makes decision tree\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "            y: numpy array of classes [num_samples, 1]\n",
    "            types: list of [num_features] with types as: cat, cont\n",
    "                eg: if num_features = 4, and last 2 features are continious then\n",
    "                    types = ['cat','cat','cont','cont']\n",
    "            max_depth: maximum depth of tree\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        self.root = self.train(X, y, types, 0, max_depth)\n",
    "\n",
    "    def predict(self, node, X):\n",
    "        '''\n",
    "        Predicted classes for X\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "        Returns:\n",
    "            y: [num_samples, 1] predicted classes\n",
    "        '''\n",
    "        if(node.is_leaf):\n",
    "            return node.value\n",
    "        else:\n",
    "            child = node.get_children(X)\n",
    "            if (child is not None): return self.predict(child, X)\n",
    "            else: return node.value\n",
    "\n",
    "    def __call__(self, X):\n",
    "        '''\n",
    "        Predicted classes for X\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "        Returns:\n",
    "            y: [num_samples, 1] predicted classes\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def get_nodes(self, node, all_nodes):\n",
    "        if(node.is_leaf):\n",
    "            all_nodes.append(node)\n",
    "            return\n",
    "        else:\n",
    "            all_nodes.append(node)\n",
    "            for child in node.children:\n",
    "                self.get_nodes(child, all_nodes)\n",
    "            return\n",
    "    \n",
    "    def post_prune(self, X_val, y_val, consecutive_constant = 0, X_train = [], y_train = [], X_test = [], y_test = []):\n",
    "        '''\n",
    "        Post prune the tree\n",
    "        Args:\n",
    "            X_val: numpy array of data [num_samples, num_features]\n",
    "            y_val: numpy array of classes [num_samples, 1]\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        all_nodes = []\n",
    "        self.get_nodes(self.root, all_nodes)\n",
    "        best_node_to_prune = None\n",
    "        for i in range(X_val.shape[0]):\n",
    "            if(self.predict(self.root, X_val[i]) == y_val[i]): correct += 1\n",
    "            else: incorrect += 1\n",
    "        val_accuracy = correct/(correct+incorrect)\n",
    "        best_accuracy = correct/(correct+incorrect)\n",
    "        for node in all_nodes:\n",
    "            if(node.is_leaf): continue\n",
    "            node.is_leaf = True\n",
    "            correct = 0\n",
    "            incorrect = 0\n",
    "            for i in range(X_val.shape[0]):\n",
    "                if(self.predict(self.root, X_val[i]) == y_val[i]): correct += 1\n",
    "                else: incorrect += 1\n",
    "            accuracy = correct/(correct+incorrect)\n",
    "            if(accuracy >= best_accuracy):\n",
    "                best_accuracy = accuracy\n",
    "                best_node_to_prune = node\n",
    "            node.is_leaf = False\n",
    "        if(best_node_to_prune is not None):\n",
    "            if(best_accuracy == val_accuracy): consecutive_constant += 1\n",
    "            else: consecutive_constant = 0\n",
    "            if(consecutive_constant == 5): return\n",
    "            best_node_to_prune.is_leaf = True\n",
    "            new_nodes =[]\n",
    "            self.get_nodes(self.root, new_nodes)\n",
    "            num_nodes = len(new_nodes)\n",
    "            train_correct = 0\n",
    "            train_incorrect = 0\n",
    "            for i in range(X_train.shape[0]):\n",
    "                if(self.predict(self.root, X_train[i]) == y_train[i]): train_correct += 1\n",
    "                else: train_incorrect += 1\n",
    "            self.train_accuracy.append([num_nodes, train_correct/(train_correct+train_incorrect)])\n",
    "            test_correct = 0\n",
    "            test_incorrect = 0\n",
    "            for i in range(X_test.shape[0]):\n",
    "                if(self.predict(self.root, X_test[i]) == y_test[i]): test_correct += 1\n",
    "                else: test_incorrect += 1\n",
    "            self.test_accuracy.append([num_nodes, test_correct/(test_correct+test_incorrect)])\n",
    "            self.val_accuracy.append([num_nodes, best_accuracy])\n",
    "            self.post_prune(X_val, y_val, consecutive_constant, X_train, y_train, X_test, y_test)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the path if you want\n",
    "X_train,y_train = get_np_array('train.csv')\n",
    "X_test, y_test = get_np_array(\"test.csv\")\n",
    "\n",
    "#only needed in part (c)\n",
    "X_val, y_val = get_np_array(\"val.csv\")\n",
    "\n",
    "types = ['cat','cat','cat',\"cat\",\"cat\",\"cont\",\"cat\",\"cat\",\"cat\" ,\"cont\",\"cont\" ,\"cont\" ]\n",
    "while(len(types) != X_train.shape[1]):\n",
    "    types = ['cat'] + types\n",
    "\n",
    "# max_depth = 10\n",
    "# tree = DTTree()\n",
    "# tree.fit(X_train,y_train,types, max_depth = max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [5, 15, 25, 35, 45, 55, 65]\n",
    "# opfile = open(\"output.txt\", \"w\")\n",
    "trainfile = open(\"train_b.txt\", \"w\")\n",
    "testfile = open(\"test_b.txt\", \"w\")\n",
    "\n",
    "for depth in depths:\n",
    "    tree = DTTree()\n",
    "    tree.fit(X_train, y_train, types, depth)\n",
    "    # opfile.write(f\"Training Complete for depth {depth}\\n\")\n",
    "    # training accuracy\n",
    "    train_correct = 0\n",
    "    train_incorrect = 0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if(tree.predict(tree.root, X_train[i]) == y_train[i]): train_correct += 1\n",
    "        else: train_incorrect += 1\n",
    "    trainfile.write(f\"({depth}, {train_correct/(train_correct+train_incorrect)})\\n\")\n",
    "    # opfile.write(f\"Training Accuracies:\\n\")\n",
    "    # opfile.write(f\"Correct: {train_correct} | Incorrect: {train_incorrect} | Accuracy: {train_correct/(train_correct+train_incorrect)}\\n\")\n",
    "    # testing accuracy\n",
    "    test_correct = 0\n",
    "    test_incorrect = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if(tree.predict(tree.root, X_test[i]) == y_test[i]): test_correct += 1\n",
    "        else: test_incorrect += 1\n",
    "    testfile.write(f\"({depth}, {test_correct/(test_correct+test_incorrect)})\\n\")\n",
    "    # opfile.write(f\"Testing Accuracies:\\n\")\n",
    "    # opfile.write(f\"Correct: {test_correct} | Incorrect: {test_incorrect} | Accuracy: {test_correct/(test_correct+test_incorrect)}\\n\")\n",
    "# opfile.close()\n",
    "testfile.close()\n",
    "trainfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and pruned for depth: 45\n"
     ]
    }
   ],
   "source": [
    "depths = [45]\n",
    "opfile = open(\"output_45.txt\", \"w\")\n",
    "trainfile = open(\"train_c_45.txt\", \"w\")\n",
    "testfile = open(\"test_c_45.txt\", \"w\")\n",
    "valfile = open(\"val_c_45.txt\", \"w\")\n",
    "node_train_files = []\n",
    "node_test_files = []\n",
    "node_val_files = []\n",
    "for depth in depths:\n",
    "    node_train_files.append(open(f\"nodes_train_{depth}.txt\", \"w\"))\n",
    "    node_test_files.append(open(f\"nodes_test_{depth}.txt\", \"w\"))\n",
    "    node_val_files.append(open(f\"nodes_val_{depth}.txt\", \"w\"))\n",
    "\n",
    "for k in range(len(depths)):\n",
    "    tree = DTTree()\n",
    "    depth = depths[k]\n",
    "    tree.fit(X_train, y_train, types, depth)\n",
    "    tree.post_prune(X_val, y_val, 0, X_train, y_train, X_test, y_test)\n",
    "    print(f\"Trained and pruned for depth: {depth}\")\n",
    "    opfile.write(f\"Training Complete for depth {depth}\\n\")\n",
    "    # training accuracy\n",
    "    train_correct = 0\n",
    "    train_incorrect = 0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if(tree.predict(tree.root, X_train[i]) == y_train[i]): train_correct += 1\n",
    "        else: train_incorrect += 1\n",
    "    trainfile.write(f\"({depth}, {train_correct/(train_correct+train_incorrect)})\\n\")\n",
    "    opfile.write(f\"Training Accuracies:\\n\")\n",
    "    opfile.write(f\"Correct: {train_correct} | Incorrect: {train_incorrect} | Accuracy: {train_correct/(train_correct+train_incorrect)}\\n\")\n",
    "    # testing accuracy\n",
    "    test_correct = 0\n",
    "    test_incorrect = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if(tree.predict(tree.root, X_test[i]) == y_test[i]): test_correct += 1\n",
    "        else: test_incorrect += 1\n",
    "    testfile.write(f\"({depth}, {test_correct/(test_correct+test_incorrect)})\\n\")\n",
    "    opfile.write(f\"Testing Accuracies:\\n\")\n",
    "    opfile.write(f\"Correct: {test_correct} | Incorrect: {test_incorrect} | Accuracy: {test_correct/(test_correct+test_incorrect)}\\n\")\n",
    "    # validation accuracy\n",
    "    val_correct = 0\n",
    "    val_incorrect = 0\n",
    "    for i in range(X_val.shape[0]):\n",
    "        if(tree.predict(tree.root, X_val[i]) == y_val[i]): val_correct += 1\n",
    "        else: val_incorrect += 1\n",
    "    valfile.write(f\"({depth}, {val_correct/(val_correct+val_incorrect)})\\n\")\n",
    "    opfile.write(f\"Validation Accuracies:\\n\")\n",
    "    opfile.write(f\"Correct: {val_correct} | Incorrect: {val_incorrect} | Accuracy: {val_correct/(val_correct+val_incorrect)}\\n\\n\")\n",
    "    # nodes\n",
    "    for j in range(len(tree.train_accuracy)):\n",
    "        node_train_files[k].write(f\"({tree.train_accuracy[j][0]}, {100 * tree.train_accuracy[j][1]})\\n\")\n",
    "        node_test_files[k].write(f\"({tree.test_accuracy[j][0]}, {100 * tree.test_accuracy[j][1]})\\n\")\n",
    "        node_val_files[k].write(f\"({tree.val_accuracy[j][0]}, {100 * tree.val_accuracy[j][1]})\\n\")\n",
    "    node_train_files[k].close()\n",
    "    node_test_files[k].close()\n",
    "    node_val_files[k].close()\n",
    "opfile.close()\n",
    "testfile.close()\n",
    "trainfile.close()\n",
    "valfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opfile.close()\n",
    "testfile.close()\n",
    "trainfile.close()\n",
    "valfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
