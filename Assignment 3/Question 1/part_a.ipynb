{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is started code for part a. \n",
    "Using this code is OPTIONAL and you may write code from scratch if you want\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = None \n",
    "\n",
    "def get_np_array(file_name):\n",
    "    global label_encoder\n",
    "    data = pd.read_csv(file_name)\n",
    "    \n",
    "    need_label_encoding = ['team','host','opp','month', 'day_match']\n",
    "    if(label_encoder is None):\n",
    "        label_encoder = OrdinalEncoder()\n",
    "        label_encoder.fit(data[need_label_encoding])\n",
    "    data_1 = pd.DataFrame(label_encoder.transform(data[need_label_encoding]), columns = label_encoder.get_feature_names_out())\n",
    "    \n",
    "    #merge the two dataframes\n",
    "    dont_need_label_encoding =  [\"year\",\"toss\",\"bat_first\",\"format\" ,\"fow\",\"score\" ,\"rpo\" ,\"result\"]\n",
    "    data_2 = data[dont_need_label_encoding]\n",
    "    final_data = pd.concat([data_1, data_2], axis=1)\n",
    "    \n",
    "    X = final_data.iloc[:,:-1]\n",
    "    y = final_data.iloc[:,-1:]\n",
    "    return X.to_numpy(), y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTNode:\n",
    "\n",
    "    def __init__(self, depth, is_leaf = False, value = 0, column = None, split_values = [], thresh = 0.0, type = 0):\n",
    "        #to split on column\n",
    "        self.depth = depth\n",
    "\n",
    "        #add children afterwards\n",
    "        self.children = []\n",
    "\n",
    "        #if leaf then also need value\n",
    "        self.is_leaf = is_leaf\n",
    "        if(self.is_leaf):\n",
    "            self.value = value\n",
    "        \n",
    "        if(not self.is_leaf):\n",
    "            self.value = value\n",
    "            self.column = column\n",
    "            # split_values is a list denoting the values on which to split on children\n",
    "            self.split_values = split_values\n",
    "            self.thresh = thresh\n",
    "            self.type = type\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "\n",
    "    def get_children(self, X):\n",
    "        '''\n",
    "        Args:\n",
    "            X: A single example np array [num_features]\n",
    "        Returns:\n",
    "            child: A DTNode\n",
    "        '''\n",
    "        if(self.type == 0):\n",
    "            for i in range(len(self.split_values)):\n",
    "                if(X[self.column] == self.split_values[i]):\n",
    "                    return self.children[i]\n",
    "            return None\n",
    "        else:\n",
    "            if(X[self.column] <= self.thresh):\n",
    "                return self.children[0]\n",
    "            else:\n",
    "                return self.children[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTTree:\n",
    "\n",
    "    def __init__(self):\n",
    "        #Tree root should be DTNode\n",
    "        self.root = None\n",
    "\n",
    "    def entropy(self, y):\n",
    "        '''\n",
    "        Return entropy of y\n",
    "        Args:\n",
    "            y: numpy array of shape [num_samples, 1]\n",
    "        Returns:\n",
    "            entropy: scalar value\n",
    "        '''\n",
    "        y_zeros = np.count_nonzero(y == 0)\n",
    "        total_y = y.shape[0]\n",
    "        if(y_zeros == total_y or y_zeros == 0):\n",
    "            return 0\n",
    "        else:\n",
    "            return -y_zeros/total_y*np.log2(y_zeros/total_y) - (total_y-y_zeros)/total_y*np.log2((total_y-y_zeros)/total_y)\n",
    "        \n",
    "    def get_best_attribute(self, X, y, types):\n",
    "        entropy_i = self.entropy(y)\n",
    "        max_gain = 0\n",
    "        best_attribute = 0\n",
    "        for i in range(X.shape[1]):\n",
    "            new_entropy = 0\n",
    "            if(types[i] == 'cont'):\n",
    "                unique_values = np.unique(X[:,i])\n",
    "                unique_values = np.sort(unique_values)\n",
    "                # set threshold to median of unique values\n",
    "                thresh = np.median(unique_values)\n",
    "                lower_indices = np.where(X[:,i] <= thresh)\n",
    "                lower_total = y[lower_indices].shape[0]\n",
    "                upper_indices = np.where(X[:,i] > thresh)\n",
    "                upper_total = y[upper_indices].shape[0]\n",
    "                new_entropy = lower_total/X.shape[0]*self.entropy(y[lower_indices]) + upper_total/X.shape[0]*self.entropy(y[upper_indices])\n",
    "            else:\n",
    "                unique_values = np.unique(X[:,i])\n",
    "                for j in range(unique_values.shape[0]):\n",
    "                    indices = np.where(X[:,i] == unique_values[j])\n",
    "                    new_entropy += indices[0].shape[0]/X.shape[0]*self.entropy(y[indices])\n",
    "            new_gain = entropy_i - new_entropy\n",
    "            if(new_gain > max_gain):\n",
    "                max_gain = new_gain\n",
    "                best_attribute = i\n",
    "        return best_attribute\n",
    "\n",
    "    def train(self, X, y, types, depth, max_depth):\n",
    "        ''' \n",
    "        Return a node of class DTNode\n",
    "        '''   \n",
    "        y_zeros = np.count_nonzero(y == 0)\n",
    "        total_y = y.shape[0]\n",
    "        if(y_zeros == total_y):\n",
    "            return DTNode(depth, True, 0, None, [], 0, 0)\n",
    "        if(y_zeros == 0):\n",
    "            return DTNode(depth, True, 1, None, [], 0, 0)\n",
    "        if(depth == max_depth):\n",
    "            if(y_zeros >= total_y/2):\n",
    "                return DTNode(depth, True, 0, None, [], 0, 0)\n",
    "            else:\n",
    "                return DTNode(depth, True, 1, None, [], 0, 0)\n",
    "        best_attribute = self.get_best_attribute(X, y, types)\n",
    "        if(types[best_attribute] == 'cont'):\n",
    "            unique_values = np.unique(X[:,best_attribute])\n",
    "            unique_values = np.sort(unique_values)\n",
    "            # set threshold to median of unique values\n",
    "            thresh = np.median(unique_values)\n",
    "            lower_indices = np.where(X[:,best_attribute] <= thresh)\n",
    "            upper_indices = np.where(X[:,best_attribute] > thresh)\n",
    "            y_zeros = np.count_nonzero(y[lower_indices] == 0)\n",
    "            total_y = y[lower_indices].shape[0]\n",
    "            value = 0 if y_zeros >= total_y/2 else 1\n",
    "            node = DTNode(depth, False, value, best_attribute, [], float(thresh), 1)\n",
    "            node.add_child(self.train(X[lower_indices], y[lower_indices], types, depth+1, max_depth))\n",
    "            node.add_child(self.train(X[upper_indices], y[upper_indices], types, depth+1, max_depth))\n",
    "            return node\n",
    "        else:\n",
    "            unique_values = np.unique(X[:,best_attribute])\n",
    "            y_zeros = np.count_nonzero(y == 0)\n",
    "            total_y = y.shape[0]\n",
    "            value = 0 if y_zeros >= total_y/2 else 1\n",
    "            node = DTNode(depth, False, value, best_attribute, unique_values, 0, 0)\n",
    "            for i in range(unique_values.shape[0]):\n",
    "                indices = np.where(X[:,best_attribute] == unique_values[i])\n",
    "                node.add_child(self.train(X[indices], y[indices], types, depth+1, max_depth))\n",
    "            return node\n",
    "        \n",
    "\n",
    "    def fit(self, X, y, types, max_depth = 10):\n",
    "        '''\n",
    "        Makes decision tree\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "            y: numpy array of classes [num_samples, 1]\n",
    "            types: list of [num_features] with types as: cat, cont\n",
    "                eg: if num_features = 4, and last 2 features are continious then\n",
    "                    types = ['cat','cat','cont','cont']\n",
    "            max_depth: maximum depth of tree\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        self.root = self.train(X, y, types, 0, max_depth)\n",
    "\n",
    "    def predict(self, node, X):\n",
    "        '''\n",
    "        Predicted classes for X\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "        Returns:\n",
    "            y: [num_samples, 1] predicted classes\n",
    "        '''\n",
    "        if(node.is_leaf):\n",
    "            return node.value\n",
    "        else:\n",
    "            child = node.get_children(X)\n",
    "            if (child is not None): return self.predict(child, X)\n",
    "            else: return node.value\n",
    "\n",
    "    def __call__(self, X):\n",
    "        '''\n",
    "        Predicted classes for X\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "        Returns:\n",
    "            y: [num_samples, 1] predicted classes\n",
    "        '''\n",
    "        \n",
    "    \n",
    "    def post_prune(self, X_val, y_val):\n",
    "        #TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = get_np_array('train.csv')\n",
    "X_test, y_test = get_np_array(\"test.csv\")\n",
    "\n",
    "types = ['cat','cat','cat',\"cat\",\"cat\",\"cont\",\"cat\",\"cat\",\"cat\" ,\"cont\",\"cont\" ,\"cont\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [5, 10, 15, 20, 25, 30, 40, 50]\n",
    "trainfile = open(\"train_a.txt\", \"w\")\n",
    "testfile = open(\"test_a.txt\", \"w\")\n",
    "\n",
    "for depth in depths:\n",
    "    tree = DTTree()\n",
    "    tree.fit(X_train, y_train, types, depth)\n",
    "    # print(f\"Training Complete for depth {depth}\")\n",
    "    # training accuracy\n",
    "    train_correct = 0\n",
    "    train_incorrect = 0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if(tree.predict(tree.root, X_train[i]) == y_train[i]): train_correct += 1\n",
    "        else: train_incorrect += 1\n",
    "    # print(f\"Training Accuracies:\")\n",
    "    # print(f\"Correct: {train_correct} | Incorrect: {train_incorrect} | Accuracy: {train_correct/(train_correct+train_incorrect)}\")\n",
    "    trainfile.write(f\"({depth}, {train_correct/(train_correct+train_incorrect)})\\n\")\n",
    "    # testing accuracy\n",
    "    test_correct = 0\n",
    "    test_incorrect = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if(tree.predict(tree.root, X_test[i]) == y_test[i]): test_correct += 1\n",
    "        else: test_incorrect += 1\n",
    "    # print(f\"Testing Accuracies:\")\n",
    "    # print(f\"Correct: {test_correct} | Incorrect: {test_incorrect} | Accuracy: {test_correct/(test_correct+test_incorrect)}\")\n",
    "    # print()\n",
    "    testfile.write(f\"({depth}, {test_correct/(test_correct+test_incorrect)})\\n\")\n",
    "trainfile.close()\n",
    "testfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 3887 | 3940 | 0.49661428388910184 | 0.5033857161108982\n",
      "Testing Data: 487 | 480 | 0.5036194415718718 | 0.4963805584281282\n"
     ]
    }
   ],
   "source": [
    "y_train_zeros = np.count_nonzero(y_train == 0)\n",
    "y_train_total = y_train.shape[0]\n",
    "y_train_ones = y_train_total - y_train_zeros\n",
    "y_test_zeros = np.count_nonzero(y_test == 0)\n",
    "y_test_total = y_test.shape[0]\n",
    "y_test_ones = y_test_total - y_test_zeros\n",
    "print(f\"Training Data: {y_train_zeros} | {y_train_ones} | {y_train_zeros/y_train_total} | {y_train_ones/y_train_total}\")\n",
    "print(f\"Testing Data: {y_test_zeros} | {y_test_ones} | {y_test_zeros/y_test_total} | {y_test_ones/y_test_total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
